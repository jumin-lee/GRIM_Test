<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>WebGPU Active GPU Write (bufA + bufB)</title>
</head>
<body>
  <h1>WebGPU 64MB × 2 Buffers – Active Compute</h1>
  <p id="status">Initializing...</p>

  <script type="module">
    const TOTAL_GB = 2;
    const BLOCK_SIZE = 64 * 1024 * 1024; // 64MB
    const TOTAL_U32_PER_BLOCK = BLOCK_SIZE / 4;
    const TOTAL_BLOCK_PAIRS = (TOTAL_GB * 1024) / 128;
    const WORKGROUP_SIZE = 64;

    let buffers = [];

    async function init() {
      if (!navigator.gpu) {
        document.getElementById("status").textContent = "❌ WebGPU not supported.";
        return;
      }

      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice();

      const shaderCode = `
        @group(0) @binding(0)
        var<storage, read_write> bufferA: array<u32>;

        @group(0) @binding(1)
        var<storage, read_write> bufferB: array<u32>;

        @compute @workgroup_size(${WORKGROUP_SIZE})
        fn main(@builtin(global_invocation_id) id : vec3<u32>) {
          let index = id.x;
          if (index < arrayLength(&bufferA)) {
            bufferA[index] = bufferA[index] + 1u;
            bufferB[index] = bufferB[index] * 2u;
          }
        }
      `;

      const module = device.createShaderModule({ code: shaderCode });

      const bindGroupLayout = device.createBindGroupLayout({
        entries: [
          { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: "storage" }},
          { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: "storage" }},
        ]
      });

      const pipelineLayout = device.createPipelineLayout({
        bindGroupLayouts: [bindGroupLayout]
      });

      const pipeline = device.createComputePipeline({
        layout: pipelineLayout,
        compute: { module, entryPoint: "main" }
      });

      for (let i = 0; i < TOTAL_BLOCK_PAIRS; i++) {
        const bufA = device.createBuffer({
          size: BLOCK_SIZE,
          usage: GPUBufferUsage.STORAGE,
        });

        const bufB = device.createBuffer({
          size: BLOCK_SIZE,
          usage: GPUBufferUsage.STORAGE,
        });

        buffers.push(bufA, bufB);

        const bindGroup = device.createBindGroup({
          layout: bindGroupLayout,
          entries: [
            { binding: 0, resource: { buffer: bufA } },
            { binding: 1, resource: { buffer: bufB } },
          ]
        });

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        pass.setPipeline(pipeline);
        pass.setBindGroup(0, bindGroup);

        const totalInvocations = TOTAL_U32_PER_BLOCK;
        const workgroupCount = Math.ceil(totalInvocations / WORKGROUP_SIZE);
        pass.dispatchWorkgroups(workgroupCount);
        pass.end();

        device.queue.submit([encoder.finish()]);
      }

      document.getElementById("status").textContent =
        `✅ ${TOTAL_GB}GB allocated as ${TOTAL_BLOCK_PAIRS} pairs of 64MB with active compute.`;
    }

    function holdForever() {
      setInterval(() => {
        console.log(`⏳ Holding ${buffers.length} × 64MB = ${(buffers.length * 64 / 1024).toFixed(2)} GB`);
      }, 10000);
    }

    init().then(holdForever);
  </script>
</body>
</html>
