<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>WebGPU GPU Memory Stress</title>
</head>
<body>
  <h1>WebGPU Active GPU Memory Allocation + Stress</h1>
  <p id="status">Initializing...</p>

  <script type="module">
    const TOTAL_GB = 50;
    const BLOCK_SIZE = 128 * 1024 * 1024; // 128MB
    const ELEMENTS = BLOCK_SIZE / 4; // u32
    const TOTAL_BLOCKS = (TOTAL_GB * 1024) / 128;
    const WORKGROUP_SIZE = 256;

    let buffers = [];

    async function init() {
      if (!navigator.gpu) {
        document.getElementById("status").textContent = "❌ WebGPU not supported.";
        return;
      }

      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice();

      const shaderCode = `
        @group(0) @binding(0)
        var<storage, read_write> data: array<u32>;

        @compute @workgroup_size(${WORKGROUP_SIZE})
        fn main(@builtin(global_invocation_id) id : vec3<u32>) {
          let i = id.x;
          if (i < arrayLength(&data)) {
            var v = data[i];
            for (var j: u32 = 0u; j < 1000u; j = j + 1u) {
              v = v + j;
              v = v ^ (j << 2u);
            }
            data[i] = v;
          }
        }
      `;

      const module = device.createShaderModule({ code: shaderCode });
      const pipeline = device.createComputePipeline({
        layout: "auto",
        compute: {
          module,
          entryPoint: "main"
        }
      });

      for (let i = 0; i < TOTAL_BLOCKS; i++) {
        const buffer = device.createBuffer({
          size: BLOCK_SIZE,
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST,
        });
        buffers.push(buffer);

        const bindGroup = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [{
            binding: 0,
            resource: { buffer }
          }]
        });

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        pass.setPipeline(pipeline);
        pass.setBindGroup(0, bindGroup);

        const numWorkgroups = Math.ceil(ELEMENTS / WORKGROUP_SIZE);
        const dispatchX = Math.min(numWorkgroups, 65535);
        const dispatchY = Math.ceil(numWorkgroups / 65535);

        pass.dispatchWorkgroups(dispatchX, dispatchY);
        pass.end();

        device.queue.submit([encoder.finish()]);
      }

      document.getElementById("status").textContent =
        `✅ ${TOTAL_GB}GB GPU buffer created and compute workload dispatched. Check nvidia-smi.`;
    }

    init();
  </script>
</body>
</html>
